Now I have all the information I need. Let me compile the complete implementation details for the MCP server.

---

# Tether MCP Server - Complete Implementation Details

## Executive Summary

This document provides exhaustive implementation details for the Tether MCP server that connects to a Raspberry Pi via dumbpipe and exposes filtered API endpoints as MCP tools. Based on research, there are critical architectural decisions to address:

**Critical Finding**: Cloud Run does NOT support stdio transport for MCP servers. It only supports **Streamable HTTP** transport. This fundamentally changes the deployment approach.

**Recommended Architecture**:
1. For Cloud Run deployment: Use Streamable HTTP transport with `rmcp-openapi`
2. For local/desktop use (Claude Desktop): Use stdio transport

This document covers both scenarios.

---

## 1. Cargo.toml - Complete Dependencies

```toml
# File: crates/tether-mcp/Cargo.toml

[package]
name = "tether-mcp"
version = "0.1.0"
edition = "2021"
authors = ["Tether Team"]
description = "MCP server for Tether - connects to Raspberry Pi via dumbpipe"
license = "MIT"
readme = "README.md"
repository = "https://github.com/your-org/tether"
keywords = ["mcp", "tether", "dumbpipe", "iroh"]
categories = ["command-line-utilities", "network-programming"]

[[bin]]
name = "tether-mcp"
path = "src/main.rs"

[dependencies]
# Async runtime
tokio = { version = "1.43", features = ["full", "process", "signal", "sync", "time", "io-util", "macros", "rt-multi-thread"] }

# MCP SDK - official Rust SDK
rmcp = { version = "0.12", features = ["server", "transport-io"] }

# OpenAPI to MCP conversion
rmcp-openapi = { version = "0.21", features = [] }

# HTTP client for fetching OpenAPI spec
reqwest = { version = "0.12", features = ["json", "rustls-tls"], default-features = false }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# URL handling
url = "2.5"

# Error handling
anyhow = "1.0"
thiserror = "2.0"

# Logging and tracing
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }

# Async utilities
futures = "0.3"

# For graceful shutdown
ctrlc = { version = "3.4", features = ["termination"] }

# HTTP headers
http = "1.2"

[dev-dependencies]
# Testing utilities
tokio-test = "0.4"
mockall = "0.13"
tempfile = "3.14"

[features]
default = []
# Use this for Cloud Run deployment (Streamable HTTP transport)
cloud-run = ["rmcp-openapi/transport-sse"]

[profile.release]
opt-level = "z"
lto = true
codegen-units = 1
panic = "abort"
strip = true
```

---

## 2. Main Implementation - Complete Source Code

```rust
// File: crates/tether-mcp/src/main.rs

//! Tether MCP Server
//!
//! This MCP server connects to a Raspberry Pi running the Tether HTTP server
//! via dumbpipe (iroh-based secure tunnel) and exposes filtered API endpoints
//! as MCP tools for AI agents.
//!
//! # Architecture
//!
//! 1. Read TETHER_DUMBPIPE_TICKET from environment
//! 2. Spawn dumbpipe as a subprocess in connect-tcp mode
//! 3. Wait for dumbpipe to establish connection
//! 4. Fetch OpenAPI spec from tunneled server
//! 5. Create MCP server with rmcp-openapi, filtering to only allowed operations
//! 6. Run server with stdio transport (for local) or HTTP transport (for Cloud Run)
//! 7. Cleanup subprocess on exit
//!
//! # Environment Variables
//!
//! - `TETHER_DUMBPIPE_TICKET`: Required. The dumbpipe ticket for connecting to the Pi
//! - `TETHER_LOCAL_PORT`: Optional. Local port for dumbpipe tunnel (default: 38080)
//! - `RUST_LOG`: Optional. Logging level (default: info)
//! - `MCP_TRANSPORT`: Optional. "stdio" or "http" (default: stdio)
//! - `MCP_HTTP_PORT`: Optional. Port for HTTP transport (default: 8080)

use std::net::SocketAddr;
use std::process::Stdio;
use std::sync::Arc;
use std::time::Duration;

use anyhow::{bail, Context, Result};
use futures::future::AbortHandle;
use reqwest::header::HeaderMap;
use rmcp::ServiceExt;
use rmcp_openapi::{Filter, Filters, Server as OpenApiServer};
use serde_json::Value;
use tokio::io::{AsyncBufReadExt, BufReader};
use tokio::process::{Child, Command};
use tokio::sync::oneshot;
use tokio::time::timeout;
use tracing::{debug, error, info, warn};
use url::Url;

/// Environment variable names
mod env_vars {
    pub const DUMBPIPE_TICKET: &str = "TETHER_DUMBPIPE_TICKET";
    pub const LOCAL_PORT: &str = "TETHER_LOCAL_PORT";
    pub const MCP_TRANSPORT: &str = "MCP_TRANSPORT";
    pub const MCP_HTTP_PORT: &str = "MCP_HTTP_PORT";
}

/// Default configuration values
mod defaults {
    pub const LOCAL_PORT: u16 = 38080;
    pub const DUMBPIPE_CONNECT_TIMEOUT_SECS: u64 = 30;
    pub const OPENAPI_FETCH_TIMEOUT_SECS: u64 = 15;
    pub const HTTP_PORT: u16 = 8080;
}

/// Allowed operation IDs that will be exposed as MCP tools.
/// These correspond to the OpenAPI operationId values from the Tether API.
///
/// CRITICAL: Only these endpoints are exposed to AI agents:
/// - Proximity check (is phone near Pi?)
/// - Passes remaining for month
/// - Pass history
/// - Use a pass (with reason)
const ALLOWED_OPERATION_IDS: &[&str] = &[
    "get_proximity",           // GET /api/proximity - Check if phone is nearby
    "get_passes_remaining",    // GET /api/passes/remaining - Passes left this month
    "get_pass_history",        // GET /api/passes/history - History of pass usage
    "use_pass",                // POST /api/passes/use - Use a pass with reason
];

/// Allowed tags for filtering (alternative approach if operationIds don't match)
const ALLOWED_TAGS: &[&str] = &[
    "proximity",
    "passes",
];

/// Custom error types for the MCP server
#[derive(Debug, thiserror::Error)]
pub enum TetherMcpError {
    #[error("TETHER_DUMBPIPE_TICKET environment variable is not set")]
    TicketNotSet,

    #[error("TETHER_DUMBPIPE_TICKET is empty or invalid: {0}")]
    InvalidTicket(String),

    #[error("Failed to spawn dumbpipe subprocess: {0}")]
    DumbpipeSpawnFailed(#[source] std::io::Error),

    #[error("Dumbpipe failed to connect within {0} seconds")]
    DumbpipeConnectionTimeout(u64),

    #[error("Dumbpipe process exited unexpectedly: {0}")]
    DumbpipeExitedUnexpectedly(String),

    #[error("Failed to fetch OpenAPI specification from Pi: {0}")]
    OpenApiFetchFailed(String),

    #[error("Pi is unreachable at {url}: {reason}")]
    PiUnreachable { url: String, reason: String },

    #[error("Invalid OpenAPI specification: {0}")]
    InvalidOpenApiSpec(String),

    #[error("MCP server error: {0}")]
    McpServerError(String),
}

/// Result type alias for this crate
pub type TetherResult<T> = Result<T, TetherMcpError>;

/// Configuration for the MCP server
#[derive(Debug, Clone)]
pub struct Config {
    /// The dumbpipe ticket for connecting to the Raspberry Pi
    pub dumbpipe_ticket: String,

    /// Local port for the dumbpipe tunnel
    pub local_port: u16,

    /// Transport mode: "stdio" or "http"
    pub transport_mode: TransportMode,

    /// Port for HTTP transport (only used when transport_mode is Http)
    pub http_port: u16,
}

/// Transport mode for the MCP server
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TransportMode {
    /// Standard input/output - for local use with Claude Desktop
    Stdio,
    /// HTTP/SSE - for Cloud Run deployment
    Http,
}

impl Config {
    /// Load configuration from environment variables
    pub fn from_env() -> TetherResult<Self> {
        // Get required ticket
        let dumbpipe_ticket = std::env::var(env_vars::DUMBPIPE_TICKET)
            .map_err(|_| TetherMcpError::TicketNotSet)?;

        if dumbpipe_ticket.trim().is_empty() {
            return Err(TetherMcpError::InvalidTicket(
                "Ticket is empty".to_string(),
            ));
        }

        // Validate ticket format (should start with expected prefix)
        if !dumbpipe_ticket.starts_with("endpoint") && !dumbpipe_ticket.starts_with("blob") {
            warn!(
                "Dumbpipe ticket has unexpected format. Expected to start with 'endpoint' or 'blob'"
            );
        }

        // Get optional local port
        let local_port = std::env::var(env_vars::LOCAL_PORT)
            .ok()
            .and_then(|s| s.parse().ok())
            .unwrap_or(defaults::LOCAL_PORT);

        // Get transport mode
        let transport_mode = match std::env::var(env_vars::MCP_TRANSPORT)
            .unwrap_or_else(|_| "stdio".to_string())
            .to_lowercase()
            .as_str()
        {
            "http" | "sse" | "streamable" => TransportMode::Http,
            _ => TransportMode::Stdio,
        };

        // Get HTTP port
        let http_port = std::env::var(env_vars::MCP_HTTP_PORT)
            .ok()
            .and_then(|s| s.parse().ok())
            .unwrap_or(defaults::HTTP_PORT);

        Ok(Self {
            dumbpipe_ticket,
            local_port,
            transport_mode,
            http_port,
        })
    }
}

/// Manages the dumbpipe subprocess lifecycle
pub struct DumbpipeManager {
    child: Child,
    local_addr: SocketAddr,
    abort_handle: Option<AbortHandle>,
}

impl DumbpipeManager {
    /// Spawn dumbpipe in connect-tcp mode and wait for it to be ready
    ///
    /// # Arguments
    /// * `ticket` - The dumbpipe ticket from the Raspberry Pi
    /// * `local_port` - Local port to bind the tunnel to
    ///
    /// # Returns
    /// A DumbpipeManager instance managing the subprocess
    pub async fn spawn_and_wait(ticket: &str, local_port: u16) -> TetherResult<Self> {
        info!("Spawning dumbpipe connect-tcp on port {}", local_port);

        let local_addr: SocketAddr = format!("127.0.0.1:{}", local_port)
            .parse()
            .expect("Valid socket address");

        // Spawn dumbpipe process
        // Command: dumbpipe connect-tcp --addr 127.0.0.1:<port> <ticket>
        let mut child = Command::new("dumbpipe")
            .arg("connect-tcp")
            .arg("--addr")
            .arg(local_addr.to_string())
            .arg(ticket)
            .stdin(Stdio::null())
            .stdout(Stdio::piped())
            .stderr(Stdio::piped())
            .kill_on_drop(true) // Ensure cleanup if dropped
            .spawn()
            .map_err(TetherMcpError::DumbpipeSpawnFailed)?;

        // Take stderr for monitoring
        let stderr = child
            .stderr
            .take()
            .expect("stderr was configured as piped");

        // Wait for dumbpipe to output a line indicating it's ready
        // Dumbpipe outputs connection status to stderr
        let ready = Self::wait_for_ready(stderr, defaults::DUMBPIPE_CONNECT_TIMEOUT_SECS).await?;

        if !ready {
            // Check if process exited
            if let Ok(Some(status)) = child.try_wait() {
                return Err(TetherMcpError::DumbpipeExitedUnexpectedly(format!(
                    "Exit status: {}",
                    status
                )));
            }
            return Err(TetherMcpError::DumbpipeConnectionTimeout(
                defaults::DUMBPIPE_CONNECT_TIMEOUT_SECS,
            ));
        }

        info!(
            "Dumbpipe connected successfully, tunnel available at {}",
            local_addr
        );

        Ok(Self {
            child,
            local_addr,
            abort_handle: None,
        })
    }

    /// Wait for dumbpipe to output a "ready" indicator
    async fn wait_for_ready(
        stderr: tokio::process::ChildStderr,
        timeout_secs: u64,
    ) -> TetherResult<bool> {
        let mut reader = BufReader::new(stderr).lines();

        let wait_future = async {
            while let Ok(Some(line)) = reader.next_line().await {
                debug!("dumbpipe: {}", line);

                // Dumbpipe outputs "listening on ..." when ready
                // Or "connected" when connection is established
                if line.contains("listening")
                    || line.contains("connected")
                    || line.contains("forwarding")
                    || line.contains("Listening")
                    || line.contains("Connected")
                {
                    return true;
                }

                // Check for error conditions
                if line.contains("error") || line.contains("Error") || line.contains("failed") {
                    error!("Dumbpipe error: {}", line);
                    return false;
                }
            }
            false
        };

        match timeout(Duration::from_secs(timeout_secs), wait_future).await {
            Ok(result) => Ok(result),
            Err(_) => {
                warn!("Timeout waiting for dumbpipe ready signal, proceeding anyway...");
                // Try to connect anyway - the ready message might not match our patterns
                Ok(true)
            }
        }
    }

    /// Get the local address of the tunnel
    pub fn local_addr(&self) -> SocketAddr {
        self.local_addr
    }

    /// Get the base URL for the tunneled HTTP server
    pub fn base_url(&self) -> Url {
        Url::parse(&format!("http://{}", self.local_addr)).expect("Valid URL")
    }

    /// Gracefully shutdown the dumbpipe process
    pub async fn shutdown(mut self) -> Result<()> {
        info!("Shutting down dumbpipe...");

        // Cancel any background tasks
        if let Some(handle) = self.abort_handle.take() {
            handle.abort();
        }

        // Send SIGTERM first for graceful shutdown
        #[cfg(unix)]
        {
            use nix::sys::signal::{self, Signal};
            use nix::unistd::Pid;

            if let Some(id) = self.child.id() {
                let _ = signal::kill(Pid::from_raw(id as i32), Signal::SIGTERM);
                // Give it a moment to shutdown gracefully
                tokio::time::sleep(Duration::from_millis(500)).await;
            }
        }

        // Force kill if still running
        let _ = self.child.kill().await;
        let _ = self.child.wait().await;

        info!("Dumbpipe shutdown complete");
        Ok(())
    }
}

impl Drop for DumbpipeManager {
    fn drop(&mut self) {
        // Note: kill_on_drop(true) handles this, but we log it
        debug!("DumbpipeManager dropped, subprocess will be killed");
    }
}

/// Fetch the OpenAPI specification from the tunneled server
async fn fetch_openapi_spec(base_url: &Url) -> TetherResult<Value> {
    let openapi_url = base_url
        .join("/api/openapi.json")
        .expect("Valid URL join");

    info!("Fetching OpenAPI spec from {}", openapi_url);

    let client = reqwest::Client::builder()
        .timeout(Duration::from_secs(defaults::OPENAPI_FETCH_TIMEOUT_SECS))
        .build()
        .map_err(|e| TetherMcpError::OpenApiFetchFailed(e.to_string()))?;

    let response = client
        .get(openapi_url.as_str())
        .send()
        .await
        .map_err(|e| {
            if e.is_connect() {
                TetherMcpError::PiUnreachable {
                    url: openapi_url.to_string(),
                    reason: "Connection refused - is the Pi running?".to_string(),
                }
            } else if e.is_timeout() {
                TetherMcpError::PiUnreachable {
                    url: openapi_url.to_string(),
                    reason: "Connection timeout".to_string(),
                }
            } else {
                TetherMcpError::OpenApiFetchFailed(e.to_string())
            }
        })?;

    if !response.status().is_success() {
        return Err(TetherMcpError::OpenApiFetchFailed(format!(
            "HTTP {} - {}",
            response.status(),
            response.status().canonical_reason().unwrap_or("Unknown")
        )));
    }

    let spec: Value = response.json().await.map_err(|e| {
        TetherMcpError::InvalidOpenApiSpec(format!("Failed to parse JSON: {}", e))
    })?;

    // Validate it looks like an OpenAPI spec
    if !spec.get("openapi").is_some() && !spec.get("swagger").is_some() {
        return Err(TetherMcpError::InvalidOpenApiSpec(
            "Missing 'openapi' or 'swagger' field".to_string(),
        ));
    }

    info!("Successfully fetched OpenAPI spec");
    debug!("OpenAPI version: {:?}", spec.get("openapi"));

    Ok(spec)
}

/// Create the filtered MCP server from OpenAPI spec
fn create_mcp_server(openapi_spec: Value, base_url: Url) -> TetherResult<OpenApiServer> {
    info!("Creating MCP server with filtered operations");

    // Build filters to only expose allowed operations
    // Using tag-based filtering as primary method
    let filters = Filters::builder()
        .tags(Filter::Include(
            ALLOWED_TAGS.iter().map(|s| s.to_string()).collect(),
        ))
        .build();

    // Create the server with the builder pattern
    let mut server = OpenApiServer::builder()
        .openapi_spec(openapi_spec)
        .base_url(base_url)
        .filters(filters)
        .build();

    // Load and parse the OpenAPI specification
    server
        .load_openapi_spec()
        .map_err(|e| TetherMcpError::InvalidOpenApiSpec(e.to_string()))?;

    let tool_count = server.tool_count();
    info!("MCP server created with {} tools", tool_count);

    if tool_count == 0 {
        warn!("No tools were generated! Check if tags match the OpenAPI spec");
        warn!("Expected tags: {:?}", ALLOWED_TAGS);
    }

    Ok(server)
}

/// Run the MCP server with stdio transport
async fn run_stdio_server(server: OpenApiServer) -> TetherResult<()> {
    info!("Starting MCP server with stdio transport");

    // Use tokio's stdin/stdout for the transport
    let transport = rmcp::transport::stdio();

    // Serve the MCP server
    let service = server
        .serve(transport)
        .await
        .map_err(|e| TetherMcpError::McpServerError(e.to_string()))?;

    info!("MCP server running, waiting for requests...");

    // Wait for the service to complete (client disconnect or shutdown)
    service
        .waiting()
        .await
        .map_err(|e| TetherMcpError::McpServerError(e.to_string()))?;

    Ok(())
}

/// Run the MCP server with HTTP/SSE transport (for Cloud Run)
#[cfg(feature = "cloud-run")]
async fn run_http_server(server: OpenApiServer, port: u16) -> TetherResult<()> {
    info!("Starting MCP server with HTTP transport on port {}", port);

    // For Cloud Run, we need to use the HTTP transport
    // This requires the transport-sse feature
    use rmcp_openapi::transport::sse::SseTransport;

    let addr: SocketAddr = format!("0.0.0.0:{}", port).parse().expect("Valid address");

    // Create SSE transport server
    let sse_server = SseTransport::new(server);

    // Run the HTTP server
    sse_server
        .serve(addr)
        .await
        .map_err(|e| TetherMcpError::McpServerError(e.to_string()))?;

    Ok(())
}

/// Setup signal handlers for graceful shutdown
fn setup_signal_handlers() -> oneshot::Receiver<()> {
    let (tx, rx) = oneshot::channel();

    tokio::spawn(async move {
        // Wait for SIGINT or SIGTERM
        #[cfg(unix)]
        {
            use tokio::signal::unix::{signal, SignalKind};
            let mut sigint = signal(SignalKind::interrupt()).expect("SIGINT handler");
            let mut sigterm = signal(SignalKind::terminate()).expect("SIGTERM handler");

            tokio::select! {
                _ = sigint.recv() => {
                    info!("Received SIGINT, initiating shutdown...");
                }
                _ = sigterm.recv() => {
                    info!("Received SIGTERM, initiating shutdown...");
                }
            }
        }

        #[cfg(not(unix))]
        {
            tokio::signal::ctrl_c()
                .await
                .expect("Ctrl+C handler");
            info!("Received Ctrl+C, initiating shutdown...");
        }

        let _ = tx.send(());
    });

    rx
}

/// Initialize logging
fn init_logging() {
    use tracing_subscriber::{fmt, prelude::*, EnvFilter};

    let filter = EnvFilter::try_from_default_env().unwrap_or_else(|_| {
        EnvFilter::new("info")
            .add_directive("tether_mcp=debug".parse().unwrap())
            .add_directive("rmcp=info".parse().unwrap())
            .add_directive("rmcp_openapi=info".parse().unwrap())
    });

    tracing_subscriber::registry()
        .with(filter)
        .with(
            fmt::layer()
                .with_target(true)
                .with_thread_ids(false)
                .with_file(false)
                .with_line_number(false)
                .with_writer(std::io::stderr) // Log to stderr, keep stdout for MCP
        )
        .init();
}

/// Main entry point
#[tokio::main]
async fn main() -> Result<()> {
    // Initialize logging first
    init_logging();

    info!("Tether MCP Server starting...");

    // Load configuration from environment
    let config = Config::from_env().context("Failed to load configuration")?;

    info!(
        "Configuration: port={}, transport={:?}",
        config.local_port, config.transport_mode
    );

    // Setup signal handlers for graceful shutdown
    let shutdown_rx = setup_signal_handlers();

    // Spawn dumbpipe and wait for connection
    let dumbpipe = DumbpipeManager::spawn_and_wait(&config.dumbpipe_ticket, config.local_port)
        .await
        .context("Failed to establish dumbpipe connection")?;

    let base_url = dumbpipe.base_url();
    info!("Dumbpipe tunnel established at {}", base_url);

    // Wrap dumbpipe in Arc for shared ownership
    let dumbpipe = Arc::new(tokio::sync::Mutex::new(Some(dumbpipe)));
    let dumbpipe_clone = Arc::clone(&dumbpipe);

    // Fetch OpenAPI spec from the tunneled server
    let openapi_spec = fetch_openapi_spec(&base_url)
        .await
        .context("Failed to fetch OpenAPI specification")?;

    // Create the MCP server with filtered operations
    let mcp_server =
        create_mcp_server(openapi_spec, base_url).context("Failed to create MCP server")?;

    // Run the server based on transport mode
    let server_future = async {
        match config.transport_mode {
            TransportMode::Stdio => run_stdio_server(mcp_server).await,
            TransportMode::Http => {
                #[cfg(feature = "cloud-run")]
                {
                    run_http_server(mcp_server, config.http_port).await
                }
                #[cfg(not(feature = "cloud-run"))]
                {
                    error!("HTTP transport requires 'cloud-run' feature");
                    Err(TetherMcpError::McpServerError(
                        "HTTP transport not available".to_string(),
                    ))
                }
            }
        }
    };

    // Run server with shutdown handling
    tokio::select! {
        result = server_future => {
            if let Err(e) = result {
                error!("MCP server error: {}", e);
            }
        }
        _ = shutdown_rx => {
            info!("Shutdown signal received");
        }
    }

    // Cleanup: shutdown dumbpipe
    info!("Cleaning up...");
    if let Some(dp) = dumbpipe_clone.lock().await.take() {
        dp.shutdown().await.context("Failed to shutdown dumbpipe")?;
    }

    info!("Tether MCP Server shutdown complete");
    Ok(())
}

// ============================================================================
// TESTS
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_config_ticket_not_set() {
        std::env::remove_var(env_vars::DUMBPIPE_TICKET);
        let result = Config::from_env();
        assert!(matches!(result, Err(TetherMcpError::TicketNotSet)));
    }

    #[test]
    fn test_config_empty_ticket() {
        std::env::set_var(env_vars::DUMBPIPE_TICKET, "");
        let result = Config::from_env();
        assert!(matches!(result, Err(TetherMcpError::InvalidTicket(_))));
        std::env::remove_var(env_vars::DUMBPIPE_TICKET);
    }

    #[test]
    fn test_config_valid() {
        std::env::set_var(env_vars::DUMBPIPE_TICKET, "endpoint12345");
        std::env::set_var(env_vars::LOCAL_PORT, "9999");
        let config = Config::from_env().unwrap();
        assert_eq!(config.local_port, 9999);
        assert_eq!(config.dumbpipe_ticket, "endpoint12345");
        std::env::remove_var(env_vars::DUMBPIPE_TICKET);
        std::env::remove_var(env_vars::LOCAL_PORT);
    }

    #[test]
    fn test_allowed_operations() {
        assert!(ALLOWED_OPERATION_IDS.contains(&"get_proximity"));
        assert!(ALLOWED_OPERATION_IDS.contains(&"get_passes_remaining"));
        assert!(ALLOWED_OPERATION_IDS.contains(&"use_pass"));
        assert!(!ALLOWED_OPERATION_IDS.contains(&"restart_system"));
    }
}
```

---

## 3. Error Handling - Detailed Scenarios

### Error: Ticket Not Set

```rust
// When TETHER_DUMBPIPE_TICKET is not set in environment
// Error message: "TETHER_DUMBPIPE_TICKET environment variable is not set"
// Exit code: 1

// User-facing message example:
error!("ERROR: Dumbpipe ticket not configured.");
error!("Please set the TETHER_DUMBPIPE_TICKET environment variable.");
error!("You can find the ticket in the Tether web UI on your Raspberry Pi.");
```

### Error: Connection Failed

```rust
// When dumbpipe cannot connect to the Pi
// Possible causes:
// 1. Pi is offline
// 2. Ticket is invalid/expired
// 3. Network issues

// Error handling in DumbpipeManager::spawn_and_wait():
if let Err(e) = child.try_wait() {
    return Err(TetherMcpError::DumbpipeSpawnFailed(e));
}

// Timeout handling:
Err(TetherMcpError::DumbpipeConnectionTimeout(30))

// User-facing guidance:
error!("ERROR: Could not connect to Raspberry Pi via dumbpipe.");
error!("Troubleshooting steps:");
error!("  1. Verify the Raspberry Pi is powered on and connected to internet");
error!("  2. Check that the ticket is current (get new ticket from Pi's web UI)");
error!("  3. Ensure no firewall is blocking the connection");
```

### Error: Pi Unreachable

```rust
// When dumbpipe connects but HTTP server is not responding
TetherMcpError::PiUnreachable {
    url: openapi_url.to_string(),
    reason: "Connection refused - is the Pi running?".to_string(),
}

// Retry logic (optional enhancement):
async fn fetch_openapi_with_retry(base_url: &Url, max_retries: u32) -> TetherResult<Value> {
    let mut last_error = None;
    for attempt in 1..=max_retries {
        match fetch_openapi_spec(base_url).await {
            Ok(spec) => return Ok(spec),
            Err(e) => {
                warn!("Attempt {}/{} failed: {}", attempt, max_retries, e);
                last_error = Some(e);
                if attempt < max_retries {
                    tokio::time::sleep(Duration::from_secs(2)).await;
                }
            }
        }
    }
    Err(last_error.unwrap())
}
```

---

## 4. Dockerfile - Multi-Stage Build

```dockerfile
# File: deploy/cloud/Dockerfile

# =============================================================================
# Stage 1: Build the Rust binary
# =============================================================================
FROM rust:1.83-bookworm AS builder

# Install build dependencies
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

# Create a new empty project for caching dependencies
WORKDIR /app

# Copy workspace files
COPY Cargo.toml Cargo.lock ./
COPY crates ./crates

# Build with release optimizations and cloud-run feature
# This enables HTTP transport for Cloud Run
RUN cargo build --release --package tether-mcp --features cloud-run

# =============================================================================
# Stage 2: Install dumbpipe
# =============================================================================
FROM rust:1.83-bookworm AS dumbpipe-builder

# Install dumbpipe from crates.io
RUN cargo install dumbpipe --locked

# =============================================================================
# Stage 3: Create minimal runtime image
# =============================================================================
FROM debian:bookworm-slim AS runtime

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Create non-root user for security
RUN useradd --create-home --shell /bin/bash tether
USER tether
WORKDIR /home/tether

# Copy binaries from builder stages
COPY --from=builder /app/target/release/tether-mcp /usr/local/bin/tether-mcp
COPY --from=dumbpipe-builder /usr/local/cargo/bin/dumbpipe /usr/local/bin/dumbpipe

# Make binaries executable
USER root
RUN chmod +x /usr/local/bin/tether-mcp /usr/local/bin/dumbpipe
USER tether

# Environment variables with defaults
ENV RUST_LOG=info
ENV MCP_TRANSPORT=http
ENV MCP_HTTP_PORT=8080
ENV TETHER_LOCAL_PORT=38080

# Expose the MCP HTTP port
EXPOSE 8080

# Health check - verify the binary exists and dumbpipe is available
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD /usr/local/bin/dumbpipe --version || exit 1

# Entry point - run the MCP server
# The TETHER_DUMBPIPE_TICKET must be set via environment variable at runtime
ENTRYPOINT ["/usr/local/bin/tether-mcp"]
```

---

## 5. Deployment Script

```bash
#!/usr/bin/env bash
# File: deploy/cloud/deploy.sh

# =============================================================================
# Tether MCP Server - Cloud Run Deployment Script
# =============================================================================
#
# This script deploys the Tether MCP server to Google Cloud Run.
#
# Prerequisites:
#   - gcloud CLI installed and configured
#   - Docker installed (for local builds)
#   - Authenticated to Google Cloud: gcloud auth login
#   - Project set: gcloud config set project YOUR_PROJECT_ID
#
# Usage:
#   ./deploy.sh [TICKET]
#
# Environment Variables:
#   TETHER_DUMBPIPE_TICKET - Required if not passed as argument
#   GCP_PROJECT_ID         - Google Cloud project ID (default: from gcloud config)
#   GCP_REGION             - Deployment region (default: us-central1)
#   SERVICE_NAME           - Cloud Run service name (default: tether-mcp)
#
# =============================================================================

set -euo pipefail

# Configuration with defaults
GCP_PROJECT_ID="${GCP_PROJECT_ID:-$(gcloud config get-value project 2>/dev/null)}"
GCP_REGION="${GCP_REGION:-us-central1}"
SERVICE_NAME="${SERVICE_NAME:-tether-mcp}"
IMAGE_NAME="gcr.io/${GCP_PROJECT_ID}/${SERVICE_NAME}"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Get the dumbpipe ticket
TICKET="${1:-${TETHER_DUMBPIPE_TICKET:-}}"

if [[ -z "$TICKET" ]]; then
    log_error "Dumbpipe ticket is required."
    echo ""
    echo "Usage: $0 <TETHER_DUMBPIPE_TICKET>"
    echo "   or: TETHER_DUMBPIPE_TICKET=<ticket> $0"
    echo ""
    echo "Get the ticket from your Raspberry Pi's web UI."
    exit 1
fi

# Validate prerequisites
if [[ -z "$GCP_PROJECT_ID" ]]; then
    log_error "GCP_PROJECT_ID not set and couldn't determine from gcloud config."
    echo "Run: gcloud config set project YOUR_PROJECT_ID"
    exit 1
fi

log_info "Deploying Tether MCP Server to Cloud Run"
log_info "  Project:  ${GCP_PROJECT_ID}"
log_info "  Region:   ${GCP_REGION}"
log_info "  Service:  ${SERVICE_NAME}"
log_info "  Image:    ${IMAGE_NAME}"

# Confirm deployment
echo ""
read -p "Continue with deployment? (y/N) " -n 1 -r
echo ""
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    log_warn "Deployment cancelled."
    exit 0
fi

# Step 1: Enable required APIs
log_info "Enabling required Google Cloud APIs..."
gcloud services enable \
    run.googleapis.com \
    containerregistry.googleapis.com \
    cloudbuild.googleapis.com \
    --project="${GCP_PROJECT_ID}"

# Step 2: Build and push container image
log_info "Building container image..."
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/../.." && pwd)"

# Submit build to Cloud Build
gcloud builds submit \
    --project="${GCP_PROJECT_ID}" \
    --tag="${IMAGE_NAME}:latest" \
    --timeout=1200s \
    "${PROJECT_ROOT}"

log_info "Container image built and pushed to ${IMAGE_NAME}:latest"

# Step 3: Deploy to Cloud Run
log_info "Deploying to Cloud Run..."

gcloud run deploy "${SERVICE_NAME}" \
    --project="${GCP_PROJECT_ID}" \
    --region="${GCP_REGION}" \
    --image="${IMAGE_NAME}:latest" \
    --platform=managed \
    --allow-unauthenticated \
    --port=8080 \
    --memory=512Mi \
    --cpu=1 \
    --min-instances=0 \
    --max-instances=10 \
    --timeout=300 \
    --concurrency=80 \
    --set-env-vars="TETHER_DUMBPIPE_TICKET=${TICKET}" \
    --set-env-vars="MCP_TRANSPORT=http" \
    --set-env-vars="MCP_HTTP_PORT=8080" \
    --set-env-vars="RUST_LOG=info,tether_mcp=debug"

# Step 4: Get the service URL
SERVICE_URL=$(gcloud run services describe "${SERVICE_NAME}" \
    --project="${GCP_PROJECT_ID}" \
    --region="${GCP_REGION}" \
    --format='value(status.url)')

log_info "Deployment complete!"
echo ""
echo "============================================"
echo "Tether MCP Server deployed successfully!"
echo "============================================"
echo ""
echo "Service URL: ${SERVICE_URL}"
echo ""
echo "To use with an MCP client, configure:"
echo "  URL: ${SERVICE_URL}/mcp"
echo "  Transport: streamable-http"
echo ""
echo "To view logs:"
echo "  gcloud run logs tail ${SERVICE_NAME} --region=${GCP_REGION}"
echo ""
echo "To update the ticket:"
echo "  gcloud run services update ${SERVICE_NAME} \\"
echo "    --region=${GCP_REGION} \\"
echo "    --set-env-vars=\"TETHER_DUMBPIPE_TICKET=<new-ticket>\""
echo ""
```

---

## 6. Local Testing Guide

### 6.1 Testing with Real Dumbpipe Connection

```bash
# Terminal 1: Run the MCP server locally
cd /path/to/tether

# Set the ticket from your Pi
export TETHER_DUMBPIPE_TICKET="endpointXXXXX..."
export RUST_LOG=debug
export MCP_TRANSPORT=stdio

# Build and run
cargo run --package tether-mcp

# The server will:
# 1. Spawn dumbpipe connect-tcp
# 2. Wait for connection
# 3. Fetch OpenAPI spec
# 4. Start listening for MCP requests on stdin
```

### 6.2 Testing with Claude Desktop

```json
// ~/.config/claude/claude_desktop_config.json (macOS)
// %APPDATA%\Claude\claude_desktop_config.json (Windows)

{
  "mcpServers": {
    "tether": {
      "command": "/path/to/tether/target/release/tether-mcp",
      "env": {
        "TETHER_DUMBPIPE_TICKET": "endpoint...",
        "RUST_LOG": "info"
      }
    }
  }
}
```

### 6.3 Mock Dumbpipe for Testing

Create a mock script that simulates dumbpipe behavior:

```bash
#!/usr/bin/env bash
# File: test/mock-dumbpipe.sh

# Mock dumbpipe for testing without a real Pi connection
# Usage: mock-dumbpipe.sh connect-tcp --addr <addr> <ticket>

# Parse arguments
ADDR=""
while [[ $# -gt 0 ]]; do
    case $1 in
        --addr)
            ADDR="$2"
            shift 2
            ;;
        connect-tcp)
            shift
            ;;
        *)
            # Ticket - ignore
            shift
            ;;
    esac
done

# Output ready message (what the MCP server looks for)
echo "Listening on ${ADDR:-127.0.0.1:38080}" >&2
echo "Connected to mock endpoint" >&2

# Keep running
exec socat TCP-LISTEN:${ADDR##*:},reuseaddr,fork TCP:localhost:3000
```

### 6.4 Integration Test with Mock HTTP Server

```rust
// File: crates/tether-mcp/tests/integration_test.rs

use std::net::SocketAddr;
use std::time::Duration;

use axum::{routing::get, Json, Router};
use serde_json::json;
use tokio::net::TcpListener;

/// Start a mock Tether HTTP server for testing
async fn start_mock_server() -> SocketAddr {
    let app = Router::new()
        .route("/api/openapi.json", get(mock_openapi))
        .route("/api/proximity", get(mock_proximity))
        .route("/api/passes/remaining", get(mock_passes_remaining))
        .route("/api/passes/history", get(mock_pass_history));

    let listener = TcpListener::bind("127.0.0.1:0").await.unwrap();
    let addr = listener.local_addr().unwrap();

    tokio::spawn(async move {
        axum::serve(listener, app).await.unwrap();
    });

    // Wait for server to start
    tokio::time::sleep(Duration::from_millis(100)).await;

    addr
}

async fn mock_openapi() -> Json<serde_json::Value> {
    Json(json!({
        "openapi": "3.0.3",
        "info": {
            "title": "Tether API",
            "version": "1.0.0"
        },
        "paths": {
            "/api/proximity": {
                "get": {
                    "operationId": "get_proximity",
                    "tags": ["proximity"],
                    "summary": "Check if phone is near the Pi",
                    "responses": {
                        "200": {
                            "description": "Proximity status"
                        }
                    }
                }
            },
            "/api/passes/remaining": {
                "get": {
                    "operationId": "get_passes_remaining",
                    "tags": ["passes"],
                    "summary": "Get remaining passes for the month",
                    "responses": {
                        "200": {
                            "description": "Passes remaining"
                        }
                    }
                }
            }
        }
    }))
}

async fn mock_proximity() -> Json<serde_json::Value> {
    Json(json!({
        "device_name": "iPhone",
        "is_nearby": true,
        "signal_strength": -45
    }))
}

async fn mock_passes_remaining() -> Json<serde_json::Value> {
    Json(json!({
        "remaining": 3,
        "total": 5,
        "month": "2025-01"
    }))
}

async fn mock_pass_history() -> Json<serde_json::Value> {
    Json(json!({
        "history": [
            {
                "used_at_utc": "2025-01-15T03:30:00Z",
                "reason": "Early flight"
            }
        ]
    }))
}

#[tokio::test]
async fn test_fetch_openapi_from_mock_server() {
    let addr = start_mock_server().await;
    let base_url = url::Url::parse(&format!("http://{}", addr)).unwrap();

    // Test OpenAPI fetch
    let client = reqwest::Client::new();
    let response = client
        .get(base_url.join("/api/openapi.json").unwrap().as_str())
        .send()
        .await
        .unwrap();

    assert!(response.status().is_success());

    let spec: serde_json::Value = response.json().await.unwrap();
    assert!(spec.get("openapi").is_some());
}
```

### 6.5 Unit Test Commands

```bash
# Run all tests
cargo test --package tether-mcp

# Run with logging
RUST_LOG=debug cargo test --package tether-mcp -- --nocapture

# Run specific test
cargo test --package tether-mcp test_config_valid

# Run integration tests (requires mock server)
cargo test --package tether-mcp --test integration_test
```

---

## 7. Important Implementation Notes

### 7.1 Cloud Run Limitations

**CRITICAL**: Cloud Run does NOT support stdio transport. The deployment must use:
- **Streamable HTTP** transport (recommended, modern)
- **SSE** transport (legacy, but still supported)

The provided implementation includes the `cloud-run` feature flag that enables HTTP transport.

### 7.2 rmcp-openapi API Notes

Based on research, the `rmcp-openapi` crate uses:

```rust
// Builder pattern for server creation
let server = Server::builder()
    .openapi_spec(json_value)
    .base_url(url)
    .filters(Filters::builder()
        .tags(Filter::Include(vec!["tag1".to_string()]))
        .build())
    .build();

// Load the spec
server.load_openapi_spec()?;

// Get tool count
let count = server.tool_count();
```

### 7.3 Async Subprocess Management Best Practices

1. **Use `kill_on_drop(true)`**: Ensures subprocess is killed if the manager is dropped unexpectedly
2. **Read stderr in a separate task**: Prevents deadlocks
3. **Timeout waiting for ready**: Don't block forever
4. **Graceful shutdown**: Send SIGTERM before SIGKILL
5. **Signal handling**: Catch SIGINT/SIGTERM for cleanup

### 7.4 OpenAPI Tag Filtering

The Tether HTTP server should tag its endpoints appropriately:

```yaml
# Expected tags in OpenAPI spec
/api/proximity:
  get:
    tags:
      - proximity
/api/passes/remaining:
  get:
    tags:
      - passes
/api/passes/history:
  get:
    tags:
      - passes
/api/passes/use:
  post:
    tags:
      - passes
```

Only `proximity` and `passes` tags are exposed to MCP clients.

---

## Sources

- [rmcp-openapi on crates.io](https://crates.io/crates/rmcp-openapi)
- [rmcp-openapi documentation](https://docs.rs/rmcp-openapi/latest/rmcp_openapi/)
- [rmcp (Rust MCP SDK)](https://docs.rs/rmcp/latest/rmcp/)
- [Model Context Protocol Rust SDK](https://github.com/modelcontextprotocol/rust-sdk)
- [dumbpipe on GitHub](https://github.com/n0-computer/dumbpipe)
- [Tokio process module](https://docs.rs/tokio/latest/tokio/process/)
- [Cloud Run MCP documentation](https://cloud.google.com/run/docs/host-mcp-servers)
- [MCP Transport Protocols comparison](https://mcpcat.io/guides/comparing-stdio-sse-streamablehttp/)

---

### Critical Files for Implementation

- `/Users/jeffrey/code/tether/crates/tether-mcp/Cargo.toml` - Package manifest with all dependencies including rmcp, rmcp-openapi, tokio, and feature flags for Cloud Run deployment
- `/Users/jeffrey/code/tether/crates/tether-mcp/src/main.rs` - Complete MCP server implementation with dumbpipe subprocess management, OpenAPI fetching, operation filtering, and dual transport support
- `/Users/jeffrey/code/tether/deploy/cloud/Dockerfile` - Multi-stage Docker build that compiles the Rust binary and includes dumbpipe for Cloud Run deployment
- `/Users/jeffrey/code/tether/deploy/cloud/deploy.sh` - Complete gcloud deployment script with environment variable configuration and service setup
- `/Users/jeffrey/code/tether/claude-spec.md` - Project specification defining the allowed endpoints (proximity, passes remaining, pass history, use pass) and architecture requirements
